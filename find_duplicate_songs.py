import os
import hashlib
from multiprocessing import Pool, cpu_count
from collections import defaultdict

# Uç›˜è·¯å¾„
USB_PATH = '/Volumes/DISK_IMG'

# æ”¯æŒçš„éŸ³ä¹æ ¼å¼
MUSIC_EXTENSIONS = {'.mp3', '.flac', '.wav', '.aac', '.m4a', '.ogg'}

def is_music_file(filename):
    return any(filename.lower().endswith(ext) for ext in MUSIC_EXTENSIONS)

def get_all_music_files(directory):
    """è·å–æ‰€æœ‰éŸ³ä¹æ–‡ä»¶åŠå…¶å¤§å°"""
    music_files = []
    for root, _, files in os.walk(directory):
        for filename in files:
            if is_music_file(filename):
                filepath = os.path.join(root, filename)
                try:
                    size = os.path.getsize(filepath)
                    music_files.append((filepath, size))
                except Exception as e:
                    print(f"âš ï¸ æ— æ³•è®¿é—®æ–‡ä»¶ {filepath}: {e}")
    return music_files

def compute_file_hash(filepath):
    """è®¡ç®—æ–‡ä»¶çš„ SHA-256"""
    sha256 = hashlib.sha256()
    try:
        with open(filepath, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b''):
                sha256.update(chunk)
        return (filepath, sha256.hexdigest())
    except Exception as e:
        print(f"âš ï¸ è¯»å–å¤±è´¥: {filepath}: {e}")
        return (filepath, None)

def group_by_size(files_with_size):
    """å°†æ–‡ä»¶æŒ‰å¤§å°åˆ†ç»„"""
    size_groups = defaultdict(list)
    for filepath, size in files_with_size:
        size_groups[size].append(filepath)
    return {size: paths for size, paths in size_groups.items() if len(paths) > 1}

def find_duplicates_by_hash(size_grouped_files):
    """å¯¹æ¯ä¸ªå¤§å°ç»„å†…çš„æ–‡ä»¶è¿›è¡Œå“ˆå¸Œæ¯”å¯¹"""
    duplicates = defaultdict(list)
    for size, filepaths in size_grouped_files.items():
        print(f"ğŸ“¦ å¤§å°ä¸º {size} å­—èŠ‚çš„æ–‡ä»¶ç»„ï¼Œå…± {len(filepaths)} ä¸ªï¼Œæ­£åœ¨è®¡ç®—å“ˆå¸Œâ€¦")
        with Pool(processes=cpu_count()) as pool:
            results = pool.map(compute_file_hash, filepaths)
        hash_map = defaultdict(list)
        for filepath, file_hash in results:
            if file_hash:
                hash_map[file_hash].append(filepath)
        for file_hash, paths in hash_map.items():
            if len(paths) > 1:
                duplicates[file_hash].extend(paths)
    return duplicates

def print_duplicates(duplicates):
    print(f"\nğŸ” æ‰¾åˆ° {len(duplicates)} ç»„é‡å¤æ–‡ä»¶ï¼š\n")
    for i, (file_hash, paths) in enumerate(duplicates.items(), 1):
        print(f"ğŸ” é‡å¤ç»„ #{i}:")
        for path in paths:
            print(f"  - {path}")
        print()

if __name__ == '__main__':
    print(f"ğŸ“‚ æ‰«æç›®å½•: {USB_PATH}")
    music_files = get_all_music_files(USB_PATH)
    print(f"ğŸ¶ æ€»å…±æ‰¾åˆ°éŸ³ä¹æ–‡ä»¶: {len(music_files)} ä¸ª")

    # æŒ‰æ–‡ä»¶å¤§å°åˆ†ç»„
    grouped_by_size = group_by_size(music_files)
    print(f"ğŸ” å‘ç° {len(grouped_by_size)} ä¸ªå¤§å°ç›¸åŒçš„æ–‡ä»¶ç»„ï¼Œå‡†å¤‡è¿›ä¸€æ­¥å“ˆå¸Œæ¯”å¯¹")

    # å¯¹å¤§å°ç›¸åŒçš„ç»„è¿›è¡Œå“ˆå¸Œå¯¹æ¯”
    duplicates = find_duplicates_by_hash(grouped_by_size)

    # è¾“å‡ºç»“æœ
    print_duplicates(duplicates)